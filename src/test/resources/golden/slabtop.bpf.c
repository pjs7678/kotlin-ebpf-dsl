// AUTO-GENERATED by kotlin-ebpf-dsl â€” do not edit

#include "vmlinux.h"
#include <bpf/bpf_helpers.h>
#include <bpf/bpf_tracing.h>
#include <bpf/bpf_core_read.h>

char LICENSE[] SEC("license") = "GPL";

struct cgroup_key {
    __u64 cgroup_id;
};

struct slab_stats {
    __u64 allocs;
    __u64 frees;
};

struct {
    __uint(type, BPF_MAP_TYPE_PERCPU_HASH);
    __uint(max_entries, 10240);
    __type(key, struct cgroup_key);
    __type(value, struct slab_stats);
} slab_stats SEC(".maps");

SEC("kprobe/kmem_cache_alloc")
int kprobe_kmem_cache_alloc(struct pt_regs *ctx)
{
    __u64 cgroup_id = bpf_get_current_cgroup_id();
    struct cgroup_key var_0 = {};
    var_0.cgroup_id = cgroup_id;
    struct slab_stats *entry_1 = bpf_map_lookup_elem(&slab_stats, &var_0);
    if (entry_1) {
        __sync_fetch_and_add(&entry_1->allocs, 1ULL);
    } else {
        struct slab_stats var_2 = {};
        var_2.allocs = 1ULL;
        bpf_map_update_elem(&slab_stats, &var_0, &var_2, 1);
    }
    return 0;
}

SEC("kprobe/kmem_cache_free")
int kprobe_kmem_cache_free(struct pt_regs *ctx)
{
    __u64 cgroup_id = bpf_get_current_cgroup_id();
    struct cgroup_key var_0 = {};
    var_0.cgroup_id = cgroup_id;
    struct slab_stats *entry_1 = bpf_map_lookup_elem(&slab_stats, &var_0);
    if (entry_1) {
        __sync_fetch_and_add(&entry_1->frees, 1ULL);
    } else {
        struct slab_stats var_2 = {};
        var_2.frees = 1ULL;
        bpf_map_update_elem(&slab_stats, &var_0, &var_2, 1);
    }
    return 0;
}
